{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('py38': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3da45907e5cd41bdac7b692b424c19725633d98a853f93b11b400b1d8951ac30"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7,preprocess_input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.train import Example\n",
    "from tensorflow.data import TFRecordDataset\n",
    "\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "source": [
    "## CFG"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CFG.debug: True\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    debug=True if \"get_ipython\" in globals() else False\n",
    "\n",
    "    batch_size=8 if debug else 512\n",
    "    epochs=10 if debug else 30\n",
    "    n_splits=4\n",
    "\n",
    "    dataset_dir=\"../input/ranzcr-clip-catheter-line-classification/\"\n",
    "    models_dir=\"./models/\" # \"../input/efficientnet-lightgbm-models/\"\n",
    "    target_cols=['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', 'NGT - Abnormal', 'NGT - Borderline',\n",
    "       'NGT - Incompletely Imaged', 'NGT - Normal', 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal', 'Swan Ganz Catheter Present']\n",
    "\n",
    "print(f\"CFG.debug: {CFG.debug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tfrecord_trial():\n",
    "    index=0\n",
    "    index_str=str(index).zfill(2)\n",
    "    filenames=[f\"../input/ranzcr-clip-catheter-line-classification/train_tfrecords/{index_str}-1881.tfrec\"]\n",
    "    raw_dataset=TFRecordDataset(filenames)\n",
    "\n",
    "    feature_description={\n",
    "        \"StudyInstanceUID\":tf.io.FixedLenFeature([],tf.string),\n",
    "        \"image\":tf.io.FixedLenFeature([],tf.string),\n",
    "    }\n",
    "\n",
    "    for raw_record in raw_dataset.take(2):\n",
    "        parsed=tf.io.parse_single_example(raw_record,feature_description)\n",
    "\n",
    "        uid=parsed[\"StudyInstanceUID\"].numpy().decode()\n",
    "        img_raw=tf.image.decode_image(parsed[\"image\"])\n",
    "        \n",
    "        print(uid)\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(img_raw,cmap=\"Greys_r\")\n",
    "        plt.title(uid)\n",
    "\n",
    "# tfrecord_trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(CFG.dataset_dir+\"train.csv\")\n",
    "\n",
    "group_kfold=GroupKFold(n_splits=CFG.n_splits)\n",
    "train_idx,val_idx=list(group_kfold.split(train,groups=train[\"PatientID\"].values))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataSequence(keras.utils.Sequence):\n",
    "    def __init__(self,batch_size,preprocessing_function,target_size=(256,256)):\n",
    "        self.batch_size=batch_size\n",
    "        self.preprocessing_function=preprocessing_function\n",
    "        self.target_size=target_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "    \n",
    "    def flow_from_dataframe(self,dataframe,directory,x_col,y_col,ext:str):\n",
    "        self.x=dataframe[x_col]+ext\n",
    "        self.y=dataframe[y_col]\n",
    "        self.directory=directory\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx=idx*self.batch_size\n",
    "        last_idx=(idx+1)*self.batch_size\n",
    "        batch_x, batch_y=self.x.iloc[start_idx:last_idx], self.y.iloc[start_idx:last_idx].values\n",
    "\n",
    "        batch_x_imgs=[]\n",
    "        for file_name in batch_x:\n",
    "            batch_x_imgs.append(self.preprocess(os.path.join(self.directory,file_name)))\n",
    "        batch_x_imgs_array=np.array(batch_x_imgs)\n",
    "\n",
    "        return batch_x_imgs_array, batch_y\n",
    "\n",
    "    def preprocess(self,path):\n",
    "        img=keras.preprocessing.image.load_img(path,target_size=self.target_size)\n",
    "        img_array=keras.preprocessing.image.img_to_array(img)/255\n",
    "        img_array=self.preprocessing_function(img_array)\n",
    "        \n",
    "        return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ImageDataSequence_from_dataframe(dataframe):\n",
    "    img_seq=ImageDataSequence(batch_size=CFG.batch_size,preprocessing_function=preprocess_input)\n",
    "    img_seq.flow_from_dataframe(dataframe=dataframe,directory=CFG.dataset_dir+\"train\",\n",
    "        x_col=\"StudyInstanceUID\",y_col=CFG.target_cols,ext=\".jpg\")\n",
    "\n",
    "    return img_seq\n",
    "\n",
    "train_seq=get_ImageDataSequence_from_dataframe(train.iloc[train_idx])\n",
    "val_seq=get_ImageDataSequence_from_dataframe(train.iloc[val_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_sequence_output(img_seq,idx):\n",
    "    imgs,labels=img_seq[idx]\n",
    "\n",
    "    fig, axes=plt.subplots(2,4,figsize=(30,15))\n",
    "    axes=axes.flatten()\n",
    "    for img,label,ax in zip(imgs,labels,axes):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(label)\n",
    "    plt.show()\n",
    "\n",
    "# check_sequence_output(train_seq,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndropout (Dropout)            (None, 2560)              0         \n_________________________________________________________________\ndense (Dense)                (None, 11)                28171     \n=================================================================\nTotal params: 28,171\nTrainable params: 28,171\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_transfer_model():\n",
    "    efficientnet_b7=EfficientNetB7(include_top=False,weights=\"imagenet\",pooling=\"avg\")\n",
    "    efficientnet_b7.trainable=False\n",
    "\n",
    "    transfer_model=Sequential([\n",
    "        efficientnet_b7,\n",
    "        Dense(11,activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    return transfer_model\n",
    "\n",
    "input_shape=(2560,)\n",
    "transfer_model=models.Sequential([\n",
    "    Dropout(0.5,input_shape=input_shape),\n",
    "    Dense(11,activation=\"sigmoid\")\n",
    "])\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\"dot\" with args ['-Tps', 'C:\\\\Users\\\\kamim\\\\AppData\\\\Local\\\\Temp\\\\tmp2mfy_pyc'] returned code: 1\n\nstdout, stderr:\n b''\nb''\n\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "1",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-575a622a1cca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransfer_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0menables\u001b[0m \u001b[1;32min\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mline\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mplots\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnotebooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m   \"\"\"\n\u001b[1;32m--> 301\u001b[1;33m   dot = model_to_dot(model,\n\u001b[0m\u001b[0;32m    302\u001b[0m                      \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m                      \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m     message = (\n\u001b[0;32m    105\u001b[0m         \u001b[1;34m'Failed to import pydot. You must `pip install pydot` '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mcheck_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# Attempt to create an image of a blank graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvocationException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1943\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1945\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1947\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstdout_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(transfer_model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_output=pd.read_csv(f\"{CFG.models_dir}efficientnet_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.merge(train,eff_output,on=\"StudyInstanceUID\")\n",
    "train_dataset=dataset.iloc[train_idx]\n",
    "val_dataset=dataset.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=Adam(learning_rate=1e-3)\n",
    "transfer_model.compile(optimizer=adam,loss=\"binary_crossentropy\",metrics=[keras.metrics.AUC(multi_label=True)])\n",
    "\n",
    "checkpoint=keras.callbacks.ModelCheckpoint(f\"{CFG.models_dir}eff_dense/checkpoint\",\n",
    "    save_weights_only=True,monitor=\"val_auc\",mode=\"max\",save_best_only=True)\n",
    "lr_reducer = keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", patience=5, min_lr=1e-6, mode='max', factor=0.5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "700/706 [============================>.] - ETA: 0s - loss: 0.2697 - auc: 0.6935\n",
      "Epoch 00001: val_auc improved from -inf to 0.71713, saving model to ./models/eff_dense\\checkpoint\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2697 - auc: 0.6934 - val_loss: 0.2622 - val_auc: 0.7171\n",
      "Epoch 2/10\n",
      "704/706 [============================>.] - ETA: 0s - loss: 0.2563 - auc: 0.7410\n",
      "Epoch 00002: val_auc improved from 0.71713 to 0.73373, saving model to ./models/eff_dense\\checkpoint\n",
      "706/706 [==============================] - 3s 5ms/step - loss: 0.2562 - auc: 0.7410 - val_loss: 0.2609 - val_auc: 0.7337\n",
      "Epoch 3/10\n",
      "704/706 [============================>.] - ETA: 0s - loss: 0.2530 - auc: 0.7576\n",
      "Epoch 00003: val_auc improved from 0.73373 to 0.74181, saving model to ./models/eff_dense\\checkpoint\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2531 - auc: 0.7574 - val_loss: 0.2578 - val_auc: 0.7418\n",
      "Epoch 4/10\n",
      "701/706 [============================>.] - ETA: 0s - loss: 0.2518 - auc: 0.7683\n",
      "Epoch 00004: val_auc did not improve from 0.74181\n",
      "706/706 [==============================] - 3s 5ms/step - loss: 0.2519 - auc: 0.7682 - val_loss: 0.2581 - val_auc: 0.7331\n",
      "Epoch 5/10\n",
      "693/706 [============================>.] - ETA: 0s - loss: 0.2516 - auc: 0.7707\n",
      "Epoch 00005: val_auc improved from 0.74181 to 0.74471, saving model to ./models/eff_dense\\checkpoint\n",
      "706/706 [==============================] - 3s 4ms/step - loss: 0.2515 - auc: 0.7707 - val_loss: 0.2572 - val_auc: 0.7447\n",
      "Epoch 6/10\n",
      "701/706 [============================>.] - ETA: 0s - loss: 0.2504 - auc: 0.7725\n",
      "Epoch 00006: val_auc did not improve from 0.74471\n",
      "706/706 [==============================] - 3s 4ms/step - loss: 0.2503 - auc: 0.7727 - val_loss: 0.2576 - val_auc: 0.7446\n",
      "Epoch 7/10\n",
      "697/706 [============================>.] - ETA: 0s - loss: 0.2502 - auc: 0.7779\n",
      "Epoch 00007: val_auc improved from 0.74471 to 0.74654, saving model to ./models/eff_dense\\checkpoint\n",
      "706/706 [==============================] - 3s 5ms/step - loss: 0.2502 - auc: 0.7776 - val_loss: 0.2567 - val_auc: 0.7465\n",
      "Epoch 8/10\n",
      "705/706 [============================>.] - ETA: 0s - loss: 0.2499 - auc: 0.7787\n",
      "Epoch 00008: val_auc did not improve from 0.74654\n",
      "706/706 [==============================] - 3s 5ms/step - loss: 0.2499 - auc: 0.7787 - val_loss: 0.2593 - val_auc: 0.7352\n",
      "Epoch 9/10\n",
      "691/706 [============================>.] - ETA: 0s - loss: 0.2503 - auc: 0.7799\n",
      "Epoch 00009: val_auc did not improve from 0.74654\n",
      "706/706 [==============================] - 3s 4ms/step - loss: 0.2503 - auc: 0.7791 - val_loss: 0.2573 - val_auc: 0.7407\n",
      "Epoch 10/10\n",
      "698/706 [============================>.] - ETA: 0s - loss: 0.2489 - auc: 0.7829\n",
      "Epoch 00010: val_auc did not improve from 0.74654\n",
      "706/706 [==============================] - 3s 4ms/step - loss: 0.2489 - auc: 0.7828 - val_loss: 0.2568 - val_auc: 0.7441\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e67e35b730>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "\"\"\"\n",
    "transfer_model.fit(x=train_seq,callbacks=[lr_reducer],max_queue_size=2,\n",
    "    epochs=CFG.epochs,steps_per_epoch=len(train_idx)//CFG.batch_size,\n",
    "    validation_data=val_seq,validation_steps=len(val_idx)//CFG.batch_size\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "transfer_model.fit(x=train_dataset.iloc[:,-input_shape[0]:],y=train_dataset[CFG.target_cols],callbacks=[checkpoint,lr_reducer],\n",
    "    epochs=CFG.epochs,validation_data=(val_dataset.iloc[:,-input_shape[0]:],val_dataset[CFG.target_cols]))"
   ]
  }
 ]
}