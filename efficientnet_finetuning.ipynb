{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('py38': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3da45907e5cd41bdac7b692b424c19725633d98a853f93b11b400b1d8951ac30"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7,preprocess_input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.train import Example\n",
    "from tensorflow.data import TFRecordDataset\n",
    "\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "source": [
    "## CFG"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CFG.debug: True\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    debug=True if \"get_ipython\" in globals() else False\n",
    "\n",
    "    batch_size=8 if debug else 64\n",
    "    epochs=10 if debug else 40\n",
    "    n_splits=4\n",
    "\n",
    "    dataset_dir=\"../input/ranzcr-clip-catheter-line-classification/\"\n",
    "    models_dir=\"./models/\" # \"../input/efficientnet-lightgbm-models/\"\n",
    "    target_cols=['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', 'NGT - Abnormal', 'NGT - Borderline',\n",
    "       'NGT - Incompletely Imaged', 'NGT - Normal', 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal', 'Swan Ganz Catheter Present']\n",
    "\n",
    "print(f\"CFG.debug: {CFG.debug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tfrecord_trial():\n",
    "    index=0\n",
    "    index_str=str(index).zfill(2)\n",
    "    filenames=[f\"../input/ranzcr-clip-catheter-line-classification/train_tfrecords/{index_str}-1881.tfrec\"]\n",
    "    raw_dataset=TFRecordDataset(filenames)\n",
    "\n",
    "    feature_description={\n",
    "        \"StudyInstanceUID\":tf.io.FixedLenFeature([],tf.string),\n",
    "        \"image\":tf.io.FixedLenFeature([],tf.string),\n",
    "    }\n",
    "\n",
    "    for raw_record in raw_dataset.take(2):\n",
    "        parsed=tf.io.parse_single_example(raw_record,feature_description)\n",
    "\n",
    "        uid=parsed[\"StudyInstanceUID\"].numpy().decode()\n",
    "        img_raw=tf.image.decode_image(parsed[\"image\"])\n",
    "        \n",
    "        print(uid)\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(img_raw,cmap=\"Greys_r\")\n",
    "        plt.title(uid)\n",
    "\n",
    "# tfrecord_trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(CFG.dataset_dir+\"train.csv\")\n",
    "\n",
    "group_kfold=GroupKFold(n_splits=CFG.n_splits)\n",
    "train_idx,val_idx=list(group_kfold.split(train,groups=train[\"PatientID\"].values))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataSequence(keras.utils.Sequence):\n",
    "    def __init__(self,batch_size,preprocessing_function,target_size=(256,256)):\n",
    "        self.batch_size=batch_size\n",
    "        self.preprocessing_function=preprocessing_function\n",
    "        self.target_size=target_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "    \n",
    "    def flow_from_dataframe(self,dataframe,directory,x_col,y_col,ext:str):\n",
    "        self.x=dataframe[x_col]+ext\n",
    "        self.y=dataframe[y_col]\n",
    "        self.directory=directory\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx=idx*self.batch_size\n",
    "        last_idx=(idx+1)*self.batch_size\n",
    "        batch_x, batch_y=self.x.iloc[start_idx:last_idx], self.y.iloc[start_idx:last_idx].values\n",
    "\n",
    "        batch_x_imgs=[]\n",
    "        for file_name in batch_x:\n",
    "            batch_x_imgs.append(self.preprocess(os.path.join(self.directory,file_name)))\n",
    "        batch_x_imgs_array=np.array(batch_x_imgs)\n",
    "\n",
    "        return batch_x_imgs_array, batch_y\n",
    "\n",
    "    def preprocess(self,path):\n",
    "        img=keras.preprocessing.image.load_img(path,target_size=self.target_size)\n",
    "        img_array=keras.preprocessing.image.img_to_array(img)/255\n",
    "        img_array=self.preprocessing_function(img_array)\n",
    "        \n",
    "        return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ImageDataSequence_from_dataframe(dataframe):\n",
    "    img_seq=ImageDataSequence(batch_size=CFG.batch_size,preprocessing_function=preprocess_input)\n",
    "    img_seq.flow_from_dataframe(dataframe=dataframe,directory=CFG.dataset_dir+\"train\",\n",
    "        x_col=\"StudyInstanceUID\",y_col=CFG.target_cols,ext=\".jpg\")\n",
    "\n",
    "    return img_seq\n",
    "\n",
    "train_seq=get_ImageDataSequence_from_dataframe(train.iloc[train_idx])\n",
    "val_seq=get_ImageDataSequence_from_dataframe(train.iloc[val_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_sequence_output(img_seq,idx):\n",
    "    imgs,labels=img_seq[idx]\n",
    "\n",
    "    fig, axes=plt.subplots(2,4,figsize=(30,15))\n",
    "    axes=axes.flatten()\n",
    "    for img,label,ax in zip(imgs,labels,axes):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(label)\n",
    "    plt.show()\n",
    "\n",
    "# check_sequence_output(train_seq,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndropout (Dropout)            (None, 2560)              0         \n_________________________________________________________________\ndense (Dense)                (None, 11)                28171     \n=================================================================\nTotal params: 28,171\nTrainable params: 28,171\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_transfer_model():\n",
    "    efficientnet_b7=EfficientNetB7(include_top=False,weights=\"imagenet\",pooling=\"avg\")\n",
    "    efficientnet_b7.trainable=False\n",
    "\n",
    "    transfer_model=Sequential([\n",
    "        efficientnet_b7,\n",
    "        Dense(11,activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    return transfer_model\n",
    "\n",
    "input_shape=(2560,)\n",
    "transfer_model=models.Sequential([\n",
    "    Dropout(0.5,input_shape=input_shape),\n",
    "    Dense(11,activation=\"sigmoid\")\n",
    "])\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_output=pd.read_csv(f\"{CFG.models_dir}efficientnet_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.merge(train,eff_output,on=\"StudyInstanceUID\")\n",
    "train_dataset=dataset.iloc[train_idx]\n",
    "val_dataset=dataset.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "706/706 [==============================] - 6s 8ms/step - loss: 0.2652 - auc: 0.7064 - val_loss: 0.2608 - val_auc: 0.7341\n",
      "Epoch 2/20\n",
      "706/706 [==============================] - 5s 7ms/step - loss: 0.2512 - auc: 0.7591 - val_loss: 0.2576 - val_auc: 0.7406\n",
      "Epoch 3/20\n",
      "706/706 [==============================] - 5s 8ms/step - loss: 0.2471 - auc: 0.7742 - val_loss: 0.2571 - val_auc: 0.7476\n",
      "Epoch 4/20\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2446 - auc: 0.7843 - val_loss: 0.2570 - val_auc: 0.7555\n",
      "Epoch 5/20\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2429 - auc: 0.7920 - val_loss: 0.2569 - val_auc: 0.7429\n",
      "Epoch 6/20\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2416 - auc: 0.7998 - val_loss: 0.2569 - val_auc: 0.7520\n",
      "Epoch 7/20\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2407 - auc: 0.8075 - val_loss: 0.2571 - val_auc: 0.7536\n",
      "Epoch 8/20\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2354 - auc: 0.8257 - val_loss: 0.2530 - val_auc: 0.7559\n",
      "Epoch 9/20\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2350 - auc: 0.8294 - val_loss: 0.2529 - val_auc: 0.7588\n",
      "Epoch 10/20\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2343 - auc: 0.8307 - val_loss: 0.2530 - val_auc: 0.7625\n",
      "Epoch 11/20\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2342 - auc: 0.8312 - val_loss: 0.2531 - val_auc: 0.7600\n",
      "Epoch 12/20\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2344 - auc: 0.8307 - val_loss: 0.2527 - val_auc: 0.7544\n",
      "Epoch 13/20\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2342 - auc: 0.8328 - val_loss: 0.2527 - val_auc: 0.7580\n",
      "Epoch 14/20\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2336 - auc: 0.8344 - val_loss: 0.2523 - val_auc: 0.7581\n",
      "Epoch 15/20\n",
      "706/706 [==============================] - 5s 7ms/step - loss: 0.2334 - auc: 0.8315 - val_loss: 0.2523 - val_auc: 0.7582\n",
      "Epoch 16/20\n",
      "706/706 [==============================] - 5s 6ms/step - loss: 0.2336 - auc: 0.8336 - val_loss: 0.2523 - val_auc: 0.7580\n",
      "Epoch 17/20\n",
      "706/706 [==============================] - 5s 7ms/step - loss: 0.2335 - auc: 0.8329 - val_loss: 0.2523 - val_auc: 0.7580\n",
      "Epoch 18/20\n",
      "706/706 [==============================] - 5s 6ms/step - loss: 0.2333 - auc: 0.8310 - val_loss: 0.2523 - val_auc: 0.7580\n",
      "Epoch 19/20\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2337 - auc: 0.8324 - val_loss: 0.2523 - val_auc: 0.7580\n",
      "Epoch 20/20\n",
      "706/706 [==============================] - 5s 7ms/step - loss: 0.2333 - auc: 0.8358 - val_loss: 0.2523 - val_auc: 0.7580\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f2b0938fd0>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "adam=Adam(learning_rate=1e-3)\n",
    "transfer_model.compile(optimizer=adam,loss=\"binary_crossentropy\",metrics=[keras.metrics.AUC(multi_label=True)])\n",
    "\n",
    "lr_reducer = keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", patience=2, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "\"\"\"\n",
    "transfer_model.fit(x=train_seq,callbacks=[lr_reducer],max_queue_size=2,\n",
    "    epochs=CFG.epochs,steps_per_epoch=len(train_idx)//CFG.batch_size,\n",
    "    validation_data=val_seq,validation_steps=len(val_idx)//CFG.batch_size\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "transfer_model.fit(x=train_dataset.iloc[:,-input_shape[0]:],y=train_dataset[CFG.target_cols],callbacks=[lr_reducer],\n",
    "    epochs=CFG.epochs,validation_data=(val_dataset.iloc[:,-input_shape[0]:],val_dataset[CFG.target_cols]))"
   ]
  }
 ]
}