{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('py38': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3da45907e5cd41bdac7b692b424c19725633d98a853f93b11b400b1d8951ac30"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7,preprocess_input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.train import Example\n",
    "from tensorflow.data import TFRecordDataset\n",
    "\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "source": [
    "## CFG"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CFG.debug: True\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    debug=True if \"get_ipython\" in globals() else False\n",
    "\n",
    "    batch_size=8 if debug else 64\n",
    "    epochs=20 if debug else 20\n",
    "    n_splits=4\n",
    "\n",
    "    dataset_dir=\"../input/ranzcr-clip-catheter-line-classification/\"\n",
    "    models_dir=\"./models/\" if debug else \"../input/efficientnet-lightgbm-models/\"\n",
    "    target_cols=['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', 'NGT - Abnormal', 'NGT - Borderline',\n",
    "       'NGT - Incompletely Imaged', 'NGT - Normal', 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal', 'Swan Ganz Catheter Present']\n",
    "\n",
    "print(f\"CFG.debug: {CFG.debug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tfrecord_trial():\n",
    "    index=0\n",
    "    index_str=str(index).zfill(2)\n",
    "    filenames=[f\"../input/ranzcr-clip-catheter-line-classification/train_tfrecords/{index_str}-1881.tfrec\"]\n",
    "    raw_dataset=TFRecordDataset(filenames)\n",
    "\n",
    "    feature_description={\n",
    "        \"StudyInstanceUID\":tf.io.FixedLenFeature([],tf.string),\n",
    "        \"image\":tf.io.FixedLenFeature([],tf.string),\n",
    "    }\n",
    "\n",
    "    for raw_record in raw_dataset.take(2):\n",
    "        parsed=tf.io.parse_single_example(raw_record,feature_description)\n",
    "\n",
    "        uid=parsed[\"StudyInstanceUID\"].numpy().decode()\n",
    "        img_raw=tf.image.decode_image(parsed[\"image\"])\n",
    "        \n",
    "        print(uid)\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(img_raw,cmap=\"Greys_r\")\n",
    "        plt.title(uid)\n",
    "\n",
    "# tfrecord_trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(CFG.dataset_dir+\"train.csv\")\n",
    "\n",
    "group_kfold=GroupKFold(n_splits=CFG.n_splits)\n",
    "train_idx,val_idx=list(group_kfold.split(train,groups=train[\"PatientID\"].values))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataSequence(keras.utils.Sequence):\n",
    "    def __init__(self,batch_size,preprocessing_function,target_size=(256,256)):\n",
    "        self.batch_size=batch_size\n",
    "        self.preprocessing_function=preprocessing_function\n",
    "        self.target_size=target_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "    \n",
    "    def flow_from_dataframe(self,dataframe,directory,x_col,y_col,ext:str):\n",
    "        self.x=dataframe[x_col]+ext\n",
    "        self.y=dataframe[y_col]\n",
    "        self.directory=directory\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx=idx*self.batch_size\n",
    "        last_idx=(idx+1)*self.batch_size\n",
    "        batch_x, batch_y=self.x.iloc[start_idx:last_idx], self.y.iloc[start_idx:last_idx].values\n",
    "\n",
    "        batch_x_imgs=[]\n",
    "        for file_name in batch_x:\n",
    "            batch_x_imgs.append(self.preprocess(os.path.join(self.directory,file_name)))\n",
    "        batch_x_imgs_array=np.array(batch_x_imgs)\n",
    "\n",
    "        return batch_x_imgs_array, batch_y\n",
    "\n",
    "    def preprocess(self,path):\n",
    "        img=keras.preprocessing.image.load_img(path,target_size=self.target_size)\n",
    "        img_array=keras.preprocessing.image.img_to_array(img)/255\n",
    "        img_array=self.preprocessing_function(img_array)\n",
    "        \n",
    "        return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ImageDataSequence_from_dataframe(dataframe):\n",
    "    img_seq=ImageDataSequence(batch_size=CFG.batch_size,preprocessing_function=preprocess_input)\n",
    "    img_seq.flow_from_dataframe(dataframe=dataframe,directory=CFG.dataset_dir+\"train\",\n",
    "        x_col=\"StudyInstanceUID\",y_col=CFG.target_cols,ext=\".jpg\")\n",
    "\n",
    "    return img_seq\n",
    "\n",
    "train_seq=get_ImageDataSequence_from_dataframe(train.iloc[train_idx])\n",
    "val_seq=get_ImageDataSequence_from_dataframe(train.iloc[val_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_sequence_output(img_seq,idx):\n",
    "    imgs,labels=img_seq[idx]\n",
    "\n",
    "    fig, axes=plt.subplots(2,4,figsize=(30,15))\n",
    "    axes=axes.flatten()\n",
    "    for img,label,ax in zip(imgs,labels,axes):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(label)\n",
    "    plt.show()\n",
    "\n",
    "# check_sequence_output(train_seq,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 11)                28171     \n=================================================================\nTotal params: 28,171\nTrainable params: 28,171\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_transfer_model():\n",
    "    efficientnet_b7=EfficientNetB7(include_top=False,weights=\"imagenet\",pooling=\"avg\")\n",
    "    efficientnet_b7.trainable=False\n",
    "\n",
    "    transfer_model=Sequential([\n",
    "        efficientnet_b7,\n",
    "        Dense(11,activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    return transfer_model\n",
    "\n",
    "input_shape=(2560,)\n",
    "transfer_model=models.Sequential([\n",
    "    Dense(11,activation=\"sigmoid\",input_shape=input_shape)\n",
    "])\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_output=pd.read_csv(f\"{CFG.models_dir}efficientnet_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.merge(train,eff_output,on=\"StudyInstanceUID\")\n",
    "train_dataset=dataset.iloc[train_idx]\n",
    "val_dataset=dataset.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "706/706 [==============================] - 5s 8ms/step - loss: 0.2635 - auc: 0.7079 - val_loss: 0.2619 - val_auc: 0.7283\n",
      "Epoch 2/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2488 - auc: 0.7617 - val_loss: 0.2582 - val_auc: 0.7486\n",
      "Epoch 3/20\n",
      "706/706 [==============================] - 4s 6ms/step - loss: 0.2442 - auc: 0.7819 - val_loss: 0.2605 - val_auc: 0.7383\n",
      "Epoch 4/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2408 - auc: 0.7926 - val_loss: 0.2605 - val_auc: 0.7548\n",
      "Epoch 5/20\n",
      "706/706 [==============================] - 3s 5ms/step - loss: 0.2389 - auc: 0.8047 - val_loss: 0.2554 - val_auc: 0.7652\n",
      "Epoch 6/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2365 - auc: 0.8099 - val_loss: 0.2545 - val_auc: 0.7392\n",
      "Epoch 7/20\n",
      "706/706 [==============================] - 3s 5ms/step - loss: 0.2349 - auc: 0.8169 - val_loss: 0.2576 - val_auc: 0.7607\n",
      "Epoch 8/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2333 - auc: 0.8229 - val_loss: 0.2536 - val_auc: 0.7396\n",
      "Epoch 9/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2274 - auc: 0.8445 - val_loss: 0.2523 - val_auc: 0.7578\n",
      "Epoch 10/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2267 - auc: 0.8493 - val_loss: 0.2524 - val_auc: 0.7655\n",
      "Epoch 11/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2265 - auc: 0.8495 - val_loss: 0.2520 - val_auc: 0.7645\n",
      "Epoch 12/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2263 - auc: 0.8506 - val_loss: 0.2526 - val_auc: 0.7632\n",
      "Epoch 13/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2262 - auc: 0.8507 - val_loss: 0.2521 - val_auc: 0.7561\n",
      "Epoch 14/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2255 - auc: 0.8532 - val_loss: 0.2519 - val_auc: 0.7565\n",
      "Epoch 15/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2254 - auc: 0.8532 - val_loss: 0.2520 - val_auc: 0.7566\n",
      "Epoch 16/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2254 - auc: 0.8531 - val_loss: 0.2519 - val_auc: 0.7586\n",
      "Epoch 17/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2253 - auc: 0.8534 - val_loss: 0.2519 - val_auc: 0.7586\n",
      "Epoch 18/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2253 - auc: 0.8535 - val_loss: 0.2519 - val_auc: 0.7586\n",
      "Epoch 19/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2253 - auc: 0.8535 - val_loss: 0.2519 - val_auc: 0.7586\n",
      "Epoch 20/20\n",
      "706/706 [==============================] - 4s 5ms/step - loss: 0.2253 - auc: 0.8535 - val_loss: 0.2519 - val_auc: 0.7586\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18765665460>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "adam=Adam(learning_rate=1e-3)\n",
    "transfer_model.compile(optimizer=adam,loss=\"binary_crossentropy\",metrics=[keras.metrics.AUC(multi_label=True)])\n",
    "\n",
    "lr_reducer = keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", patience=3, min_lr=1e-6, mode='max')\n",
    "\n",
    "\"\"\"\n",
    "transfer_model.fit(x=train_seq,callbacks=[lr_reducer],max_queue_size=2,\n",
    "    epochs=CFG.epochs,steps_per_epoch=len(train_idx)//CFG.batch_size,\n",
    "    validation_data=val_seq,validation_steps=len(val_idx)//CFG.batch_size\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "transfer_model.fit(x=train_dataset.iloc[:,-input_shape[0]:],y=train_dataset[CFG.target_cols],callbacks=[lr_reducer],\n",
    "    epochs=CFG.epochs,validation_data=(val_dataset.iloc[:,-input_shape[0]:],val_dataset[CFG.target_cols]))"
   ]
  }
 ]
}