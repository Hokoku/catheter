{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('py38': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3da45907e5cd41bdac7b692b424c19725633d98a853f93b11b400b1d8951ac30"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import models\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "source": [
    "## CFG"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    dataset_dir=\"../input/ranzcr-clip-catheter-line-classification/\"\n",
    "    models_dir=\"./models/\"\n",
    "\n",
    "    n_folds=10\n",
    "    target_cols=['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', 'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal', 'Swan Ganz Catheter Present']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30083/30083 [00:56<00:00, 530.07it/s]\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv(f\"{CFG.dataset_dir}train.csv\")\n",
    "\n",
    "npz=np.load(\"../input/effnet_tuned_output.npz\")\n",
    "features_list=[npz[uid] for uid in tqdm(train[\"StudyInstanceUID\"])]\n",
    "features=np.array(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(train):\n",
    "    fold=train.copy()\n",
    "    splitter=GroupKFold(n_splits=CFG.n_folds)\n",
    "    for n,(train_idx,val_idx) in enumerate(splitter.split(train,groups=train[\"PatientID\"])):\n",
    "        fold.loc[val_idx,\"folds\"]=n\n",
    "    fold[\"folds\"]=fold[\"folds\"].astype(int)\n",
    "    return fold\n",
    "\n",
    "fold=get_fold(train)"
   ]
  },
  {
   "source": [
    "### AutoEncoderで次元削減する"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "def compress_with_autoencoder(features):\n",
    "    scaler=pickle.load(open(f\"{CFG.models_dir}minmaxscaler_effnet_best.pickle\",\"rb\"))\n",
    "    X=scaler.transform(features)\n",
    "\n",
    "    autoencoder_dir=f\"{CFG.models_dir}autoencoder_best/\"\n",
    "    with open(f\"{autoencoder_dir}model.json\",\"rt\") as f:\n",
    "        model_json=f.read()\n",
    "    autoencoder=models.model_from_json(model_json)\n",
    "    autoencoder.load_weights(f\"{autoencoder_dir}ckpt\")\n",
    "\n",
    "    layer_name=\"dense_1\"\n",
    "    compressing_model=models.Model(inputs=autoencoder.input,outputs=autoencoder.get_layer(layer_name).output)\n",
    "\n",
    "    ae_pred=compressing_model.predict(X)\n",
    "    ae_pred_df=pd.DataFrame(ae_pred)\n",
    "\n",
    "    return ae_pred_df\n",
    "\n",
    "X=compress_with_autoencoder(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "              0         1          2          5          7          10  \\\n0      15.975632  2.598794  28.477423  10.108122  17.627970  31.613720   \n1      18.253782  1.896787  29.749559  10.739809  13.350595  31.290251   \n2      21.113445  6.490278  37.285770  14.575913  21.804926  35.283077   \n3      20.578976  4.586390  35.011791  13.960997  21.497570  32.601837   \n4      21.259962  1.174299  32.234509  14.236063  16.974590  39.146740   \n...          ...       ...        ...        ...        ...        ...   \n30078  16.151951  3.921811  26.502596   8.552945  14.540611  26.849852   \n30079  23.679729  4.203311  36.897343  17.462229  23.211433  39.100208   \n30080  16.755604  4.080050  27.205835   8.939780  14.894520  25.983810   \n30081  22.814905  7.761188  39.397442  15.905684  23.822273  37.408810   \n30082  23.388817  2.695583  30.088604  12.893304  11.467754  37.309071   \n\n              11         12         15         16  ...         82         83  \\\n0      13.680086  29.980919  43.547512  35.329071  ...  12.405697  13.718209   \n1      17.574186  31.453568  43.391998  34.259590  ...   5.430474  13.750910   \n2      19.106745  31.540510  46.289322  41.946312  ...  15.540805  21.033930   \n3      17.303205  29.510359  43.780560  40.917683  ...  13.879373  19.960590   \n4      21.910166  35.963516  46.976074  42.572781  ...   8.802354  17.031981   \n...          ...        ...        ...        ...  ...        ...        ...   \n30078  13.892633  25.795586  40.366196  31.494781  ...  10.371680  13.132877   \n30079  22.401089  35.309669  48.646877  47.263458  ...  12.679943  20.948107   \n30080  14.067039  24.994057  38.945438  30.419767  ...  10.008484  13.232534   \n30081  21.016159  32.534973  49.597984  44.645538  ...  16.606625  23.253817   \n30082  23.725920  41.812176  57.456711  41.398396  ...   4.621101  14.528334   \n\n             84         88        89         93         94        95  \\\n0      0.000000  18.162479  2.853658  11.579735  33.015427  0.000000   \n1      4.117984  19.033838  1.866350  20.918510  33.531281  1.492328   \n2      3.303513  14.330857  6.227699  19.798576  36.662624  0.000000   \n3      5.534728  11.691888  6.688281  18.260839  35.191917  0.000000   \n4      0.000000  19.087912  3.070636  23.272400  36.912308  0.000000   \n...         ...        ...       ...        ...        ...       ...   \n30078  3.722044  15.343826  3.803681  14.631236  31.437992  0.000000   \n30079  1.561532  15.763021  6.220365  23.946432  36.339615  0.000000   \n30080  4.731323  14.609595  3.877387  14.661573  30.467600  0.774718   \n30081  5.279211  14.986032  7.915530  23.222389  38.238205  0.220387   \n30082  2.978813  24.403536  4.489664  31.162514  39.293861  4.050951   \n\n             96        97  \n0      1.013134  0.000000  \n1      0.169154  0.000000  \n2      3.031176  0.000000  \n3      4.315998  0.000000  \n4      3.029698  0.000000  \n...         ...       ...  \n30078  1.348760  0.000000  \n30079  4.819793  0.000000  \n30080  1.180949  0.000000  \n30081  4.085468  0.000000  \n30082  2.633223  4.079183  \n\n[30083 rows x 61 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>5</th>\n      <th>7</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>15</th>\n      <th>16</th>\n      <th>...</th>\n      <th>82</th>\n      <th>83</th>\n      <th>84</th>\n      <th>88</th>\n      <th>89</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15.975632</td>\n      <td>2.598794</td>\n      <td>28.477423</td>\n      <td>10.108122</td>\n      <td>17.627970</td>\n      <td>31.613720</td>\n      <td>13.680086</td>\n      <td>29.980919</td>\n      <td>43.547512</td>\n      <td>35.329071</td>\n      <td>...</td>\n      <td>12.405697</td>\n      <td>13.718209</td>\n      <td>0.000000</td>\n      <td>18.162479</td>\n      <td>2.853658</td>\n      <td>11.579735</td>\n      <td>33.015427</td>\n      <td>0.000000</td>\n      <td>1.013134</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18.253782</td>\n      <td>1.896787</td>\n      <td>29.749559</td>\n      <td>10.739809</td>\n      <td>13.350595</td>\n      <td>31.290251</td>\n      <td>17.574186</td>\n      <td>31.453568</td>\n      <td>43.391998</td>\n      <td>34.259590</td>\n      <td>...</td>\n      <td>5.430474</td>\n      <td>13.750910</td>\n      <td>4.117984</td>\n      <td>19.033838</td>\n      <td>1.866350</td>\n      <td>20.918510</td>\n      <td>33.531281</td>\n      <td>1.492328</td>\n      <td>0.169154</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21.113445</td>\n      <td>6.490278</td>\n      <td>37.285770</td>\n      <td>14.575913</td>\n      <td>21.804926</td>\n      <td>35.283077</td>\n      <td>19.106745</td>\n      <td>31.540510</td>\n      <td>46.289322</td>\n      <td>41.946312</td>\n      <td>...</td>\n      <td>15.540805</td>\n      <td>21.033930</td>\n      <td>3.303513</td>\n      <td>14.330857</td>\n      <td>6.227699</td>\n      <td>19.798576</td>\n      <td>36.662624</td>\n      <td>0.000000</td>\n      <td>3.031176</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20.578976</td>\n      <td>4.586390</td>\n      <td>35.011791</td>\n      <td>13.960997</td>\n      <td>21.497570</td>\n      <td>32.601837</td>\n      <td>17.303205</td>\n      <td>29.510359</td>\n      <td>43.780560</td>\n      <td>40.917683</td>\n      <td>...</td>\n      <td>13.879373</td>\n      <td>19.960590</td>\n      <td>5.534728</td>\n      <td>11.691888</td>\n      <td>6.688281</td>\n      <td>18.260839</td>\n      <td>35.191917</td>\n      <td>0.000000</td>\n      <td>4.315998</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21.259962</td>\n      <td>1.174299</td>\n      <td>32.234509</td>\n      <td>14.236063</td>\n      <td>16.974590</td>\n      <td>39.146740</td>\n      <td>21.910166</td>\n      <td>35.963516</td>\n      <td>46.976074</td>\n      <td>42.572781</td>\n      <td>...</td>\n      <td>8.802354</td>\n      <td>17.031981</td>\n      <td>0.000000</td>\n      <td>19.087912</td>\n      <td>3.070636</td>\n      <td>23.272400</td>\n      <td>36.912308</td>\n      <td>0.000000</td>\n      <td>3.029698</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30078</th>\n      <td>16.151951</td>\n      <td>3.921811</td>\n      <td>26.502596</td>\n      <td>8.552945</td>\n      <td>14.540611</td>\n      <td>26.849852</td>\n      <td>13.892633</td>\n      <td>25.795586</td>\n      <td>40.366196</td>\n      <td>31.494781</td>\n      <td>...</td>\n      <td>10.371680</td>\n      <td>13.132877</td>\n      <td>3.722044</td>\n      <td>15.343826</td>\n      <td>3.803681</td>\n      <td>14.631236</td>\n      <td>31.437992</td>\n      <td>0.000000</td>\n      <td>1.348760</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>30079</th>\n      <td>23.679729</td>\n      <td>4.203311</td>\n      <td>36.897343</td>\n      <td>17.462229</td>\n      <td>23.211433</td>\n      <td>39.100208</td>\n      <td>22.401089</td>\n      <td>35.309669</td>\n      <td>48.646877</td>\n      <td>47.263458</td>\n      <td>...</td>\n      <td>12.679943</td>\n      <td>20.948107</td>\n      <td>1.561532</td>\n      <td>15.763021</td>\n      <td>6.220365</td>\n      <td>23.946432</td>\n      <td>36.339615</td>\n      <td>0.000000</td>\n      <td>4.819793</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>30080</th>\n      <td>16.755604</td>\n      <td>4.080050</td>\n      <td>27.205835</td>\n      <td>8.939780</td>\n      <td>14.894520</td>\n      <td>25.983810</td>\n      <td>14.067039</td>\n      <td>24.994057</td>\n      <td>38.945438</td>\n      <td>30.419767</td>\n      <td>...</td>\n      <td>10.008484</td>\n      <td>13.232534</td>\n      <td>4.731323</td>\n      <td>14.609595</td>\n      <td>3.877387</td>\n      <td>14.661573</td>\n      <td>30.467600</td>\n      <td>0.774718</td>\n      <td>1.180949</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>30081</th>\n      <td>22.814905</td>\n      <td>7.761188</td>\n      <td>39.397442</td>\n      <td>15.905684</td>\n      <td>23.822273</td>\n      <td>37.408810</td>\n      <td>21.016159</td>\n      <td>32.534973</td>\n      <td>49.597984</td>\n      <td>44.645538</td>\n      <td>...</td>\n      <td>16.606625</td>\n      <td>23.253817</td>\n      <td>5.279211</td>\n      <td>14.986032</td>\n      <td>7.915530</td>\n      <td>23.222389</td>\n      <td>38.238205</td>\n      <td>0.220387</td>\n      <td>4.085468</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>30082</th>\n      <td>23.388817</td>\n      <td>2.695583</td>\n      <td>30.088604</td>\n      <td>12.893304</td>\n      <td>11.467754</td>\n      <td>37.309071</td>\n      <td>23.725920</td>\n      <td>41.812176</td>\n      <td>57.456711</td>\n      <td>41.398396</td>\n      <td>...</td>\n      <td>4.621101</td>\n      <td>14.528334</td>\n      <td>2.978813</td>\n      <td>24.403536</td>\n      <td>4.489664</td>\n      <td>31.162514</td>\n      <td>39.293861</td>\n      <td>4.050951</td>\n      <td>2.633223</td>\n      <td>4.079183</td>\n    </tr>\n  </tbody>\n</table>\n<p>30083 rows × 61 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "valuless_columns=[3, 4, 6, 8, 9, 13, 14, 17, 18, 23, 27, 35, 36, 37, 38, 44, 45,\n",
    "            47, 50, 51, 52, 57, 58, 61, 62, 67, 68, 72, 73, 74, 76, 85, 86, 87,\n",
    "            90, 91, 92, 98, 99]\n",
    "X_dropped=X.drop(columns=valuless_columns)\n",
    "display(X_dropped)"
   ]
  },
  {
   "source": [
    "## パラメータを最適化する"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_fold=0\n",
    "train_idx=(fold[\"folds\"]!=target_fold)\n",
    "val_idx=(fold[\"folds\"]==target_fold)\n",
    "\n",
    "X_train,X_val=X_dropped[train_idx],X_dropped[val_idx]\n",
    "y_train,y_val=train[train_idx],train[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ue: 0.9992211377304545 and parameters: {'lambda_l1': 0.010968265726788731, 'lambda_l2': 0.00018513724320121008}. Best is trial 43 with value: 0.9993640934634723.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  20%|##        | 4/20 [00:02<00:10,  1.54it/s][100]\tvalid_0's auc: 0.999221\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "regularization_factors, val_score: 0.999527:  25%|##5       | 5/20 [00:03<00:09,  1.55it/s]\u001b[32m[I 2021-03-16 18:55:49,157]\u001b[0m Trial 47 finished with value: 0.9994035295277531 and parameters: {'lambda_l1': 2.6638198961999587e-07, 'lambda_l2': 2.5257328883401513}. Best is trial 47 with value: 0.9994035295277531.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  25%|##5       | 5/20 [00:03<00:09,  1.55it/s][100]\tvalid_0's auc: 0.999404\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  30%|###       | 6/20 [00:03<00:09,  1.53it/s]\u001b[32m[I 2021-03-16 18:55:49,823]\u001b[0m Trial 48 finished with value: 0.9990387459331559 and parameters: {'lambda_l1': 5.844322242957515e-06, 'lambda_l2': 0.0025385220200853263}. Best is trial 47 with value: 0.9994035295277531.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  30%|###       | 6/20 [00:03<00:09,  1.53it/s][100]\tvalid_0's auc: 0.999039\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  35%|###5      | 7/20 [00:04<00:08,  1.52it/s]\u001b[32m[I 2021-03-16 18:55:50,491]\u001b[0m Trial 49 finished with value: 0.9992852213349108 and parameters: {'lambda_l1': 0.01828808348956327, 'lambda_l2': 0.044281212143689054}. Best is trial 47 with value: 0.9994035295277531.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  35%|###5      | 7/20 [00:04<00:08,  1.52it/s][100]\tvalid_0's auc: 0.999285\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  40%|####      | 8/20 [00:05<00:07,  1.51it/s]\u001b[32m[I 2021-03-16 18:55:51,160]\u001b[0m Trial 50 finished with value: 0.9994133885438233 and parameters: {'lambda_l1': 0.00020025421145560836, 'lambda_l2': 0.00010465290519844023}. Best is trial 50 with value: 0.9994133885438233.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  40%|####      | 8/20 [00:05<00:07,  1.51it/s][100]\tvalid_0's auc: 0.999413\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  45%|####5     | 9/20 [00:05<00:07,  1.50it/s]\u001b[32m[I 2021-03-16 18:55:51,840]\u001b[0m Trial 51 finished with value: 0.9991324065858227 and parameters: {'lambda_l1': 0.025954478893979123, 'lambda_l2': 0.0006895755807919364}. Best is trial 50 with value: 0.9994133885438233.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  45%|####5     | 9/20 [00:05<00:07,  1.50it/s][100]\tvalid_0's auc: 0.999132\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  50%|#####     | 10/20 [00:06<00:06,  1.50it/s]\u001b[32m[I 2021-03-16 18:55:52,512]\u001b[0m Trial 52 finished with value: 0.9991324065858227 and parameters: {'lambda_l1': 0.43845866640710707, 'lambda_l2': 2.1463232208200562e-05}. Best is trial 50 with value: 0.9994133885438233.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  50%|#####     | 10/20 [00:06<00:06,  1.50it/s][LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's auc: 0.999132\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  55%|#####5    | 11/20 [00:07<00:06,  1.48it/s]\u001b[32m[I 2021-03-16 18:55:53,204]\u001b[0m Trial 53 finished with value: 0.9994676131322094 and parameters: {'lambda_l1': 4.208869646757619e-05, 'lambda_l2': 4.519647834719702e-07}. Best is trial 53 with value: 0.9994676131322094.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  55%|#####5    | 11/20 [00:07<00:06,  1.48it/s][100]\tvalid_0's auc: 0.999468\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  60%|######    | 12/20 [00:07<00:05,  1.48it/s]\u001b[32m[I 2021-03-16 18:55:53,880]\u001b[0m Trial 54 finished with value: 0.9991915606822439 and parameters: {'lambda_l1': 7.078650393549535e-05, 'lambda_l2': 1.3704979181236211e-08}. Best is trial 53 with value: 0.9994676131322094.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  60%|######    | 12/20 [00:07<00:05,  1.48it/s][100]\tvalid_0's auc: 0.999192\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  65%|######5   | 13/20 [00:08<00:04,  1.47it/s]\u001b[32m[I 2021-03-16 18:55:54,571]\u001b[0m Trial 55 finished with value: 0.9992605737947353 and parameters: {'lambda_l1': 0.0001981152653965013, 'lambda_l2': 3.968622205222778e-07}. Best is trial 53 with value: 0.9994676131322094.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  65%|######5   | 13/20 [00:08<00:04,  1.47it/s][100]\tvalid_0's auc: 0.999261\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  70%|#######   | 14/20 [00:09<00:04,  1.47it/s]\u001b[32m[I 2021-03-16 18:55:55,248]\u001b[0m Trial 56 finished with value: 0.9993000098590161 and parameters: {'lambda_l1': 6.1739612265202555e-06, 'lambda_l2': 1.4441952977151729e-06}. Best is trial 53 with value: 0.9994676131322094.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  70%|#######   | 14/20 [00:09<00:04,  1.47it/s][100]\tvalid_0's auc: 0.9993\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  75%|#######5  | 15/20 [00:09<00:03,  1.47it/s]\u001b[32m[I 2021-03-16 18:55:55,926]\u001b[0m Trial 57 finished with value: 0.9995218377205954 and parameters: {'lambda_l1': 0.0006097832414123138, 'lambda_l2': 2.8141684608245654e-08}. Best is trial 57 with value: 0.9995218377205954.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  75%|#######5  | 15/20 [00:09<00:03,  1.47it/s][100]\tvalid_0's auc: 0.999522\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  80%|########  | 16/20 [00:10<00:02,  1.47it/s]\u001b[32m[I 2021-03-16 18:55:56,613]\u001b[0m Trial 58 finished with value: 0.998945085280489 and parameters: {'lambda_l1': 0.001431240007710019, 'lambda_l2': 1.3661002817502726e-08}. Best is trial 57 with value: 0.9995218377205954.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  80%|########  | 16/20 [00:10<00:02,  1.47it/s][100]\tvalid_0's auc: 0.998945\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  85%|########5 | 17/20 [00:11<00:02,  1.47it/s]\u001b[32m[I 2021-03-16 18:55:57,295]\u001b[0m Trial 59 finished with value: 0.9995267672286305 and parameters: {'lambda_l1': 4.265204164359092e-06, 'lambda_l2': 3.2322504523781095e-07}. Best is trial 59 with value: 0.9995267672286305.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  85%|########5 | 17/20 [00:11<00:02,  1.47it/s][100]\tvalid_0's auc: 0.999527\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  90%|######### | 18/20 [00:12<00:01,  1.47it/s]\u001b[32m[I 2021-03-16 18:55:57,976]\u001b[0m Trial 60 finished with value: 0.9993000098590161 and parameters: {'lambda_l1': 3.5809321288812755e-07, 'lambda_l2': 8.378383905423629e-08}. Best is trial 59 with value: 0.9995267672286305.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  90%|######### | 18/20 [00:12<00:01,  1.47it/s][100]\tvalid_0's auc: 0.9993\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527:  95%|#########5| 19/20 [00:12<00:00,  1.44it/s]\u001b[32m[I 2021-03-16 18:55:58,695]\u001b[0m Trial 61 finished with value: 0.9993936705116829 and parameters: {'lambda_l1': 7.391001375997763e-07, 'lambda_l2': 6.689228747237567e-06}. Best is trial 59 with value: 0.9995267672286305.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527:  95%|#########5| 19/20 [00:12<00:00,  1.44it/s][100]\tvalid_0's auc: 0.999394\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "regularization_factors, val_score: 0.999527: 100%|##########| 20/20 [00:13<00:00,  1.45it/s]\u001b[32m[I 2021-03-16 18:55:59,377]\u001b[0m Trial 62 finished with value: 0.9993000098590161 and parameters: {'lambda_l1': 1.2107053582093645e-08, 'lambda_l2': 8.339800604157324e-08}. Best is trial 59 with value: 0.9995267672286305.\u001b[0m\n",
      "regularization_factors, val_score: 0.999527: 100%|##########| 20/20 [00:13<00:00,  1.49it/s]\n",
      "min_data_in_leaf, val_score: 0.999527:   0%|          | 0/5 [00:00<?, ?it/s][100]\tvalid_0's auc: 0.9993\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "min_data_in_leaf, val_score: 0.999527:  20%|##        | 1/5 [00:00<00:02,  1.42it/s]\u001b[32m[I 2021-03-16 18:56:00,098]\u001b[0m Trial 63 finished with value: 0.9992112787143843 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.9992112787143843.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.999527:  20%|##        | 1/5 [00:00<00:02,  1.42it/s][100]\tvalid_0's auc: 0.999211\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "min_data_in_leaf, val_score: 0.999527:  40%|####      | 2/5 [00:01<00:02,  1.21it/s]\u001b[32m[I 2021-03-16 18:56:01,012]\u001b[0m Trial 64 finished with value: 0.9991324065858227 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.9992112787143843.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.999527:  40%|####      | 2/5 [00:01<00:02,  1.21it/s][100]\tvalid_0's auc: 0.999132\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "min_data_in_leaf, val_score: 0.999527:  60%|######    | 3/5 [00:02<00:01,  1.31it/s]\u001b[32m[I 2021-03-16 18:56:01,699]\u001b[0m Trial 65 finished with value: 0.9991028295376121 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.9992112787143843.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.999527:  60%|######    | 3/5 [00:02<00:01,  1.31it/s][100]\tvalid_0's auc: 0.999103\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "min_data_in_leaf, val_score: 0.999527:  80%|########  | 4/5 [00:02<00:00,  1.39it/s]\u001b[32m[I 2021-03-16 18:56:02,349]\u001b[0m Trial 66 finished with value: 0.9992014196983141 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.9992112787143843.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.999527:  80%|########  | 4/5 [00:02<00:00,  1.39it/s][100]\tvalid_0's auc: 0.999201\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15563\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n",
      "min_data_in_leaf, val_score: 0.999527: 100%|##########| 5/5 [00:03<00:00,  1.45it/s]\u001b[32m[I 2021-03-16 18:56:02,984]\u001b[0m Trial 67 finished with value: 0.9993246573991915 and parameters: {'min_child_samples': 25}. Best is trial 67 with value: 0.9993246573991915.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.999527: 100%|##########| 5/5 [00:03<00:00,  1.39it/s][100]\tvalid_0's auc: 0.999325\n",
      "Wall time: 13min 26s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from optuna.integration import lightgbm as lgb\n",
    "\n",
    "def optimize_params():\n",
    "    for n,col_name in enumerate(CFG.target_cols):\n",
    "        y_train_col,y_val_col=y_train[col_name],y_val[col_name]\n",
    "\n",
    "        lgb_train=lgb.Dataset(X_train,label=y_train_col)\n",
    "        lgb_val=lgb.Dataset(X_val,label=y_val_col,reference=lgb_train)\n",
    "        \n",
    "        params={\n",
    "            \"task\":\"train\",\n",
    "            \"boosting_type\":\"gbdt\",\n",
    "            \"objective\":\"binary\",\n",
    "            \"metric\":\"auc\",\n",
    "            \"learning_rate\":0.1, #0.01\n",
    "            \"num_iterations\":100 #1000\n",
    "            # \"early_stopping_rounds\":200, #early_stopping_roundsを指定しないとbest_iterationは保存されない\n",
    "        }\n",
    "\n",
    "        opt=lgb.train(params,lgb_train,valid_sets=lgb_val, verbose_eval=100)\n",
    "        pickle.dump(opt.params,open(f\"{CFG.models_dir}lgbm_effnet_best/params_{n}.pickle\",\"wb\"))\n",
    "\n",
    "optimize_params()"
   ]
  },
  {
   "source": [
    "### 最適化に要した時間\n",
    "lr num_it, default: 19min 49s  \n",
    "lr \\*0.1, num_it \\*10: 2h 16min 1s  \n",
    "lr num_it,default: 14min 26s  \n",
    "lr num_it,default: 13mins 1s  \n",
    "lr num_it,default: 14min 38s  \n",
    "lr \\*0.1, num_it \\*10: 1h 42min 3s  \n",
    "best, dropped: 1h 38min 35s  \n",
    "lr num_it, default: 13min 26s"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 得られたパラメータで予測する"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sitive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "[LightGBM] [Info] Number of positive: 494, number of negative: 26581\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27075, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018246 -> initscore=-3.985416\n",
      "[LightGBM] [Info] Start training from score -3.985416\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "[LightGBM] [Info] Number of positive: 2437, number of negative: 24638\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27075, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.090009 -> initscore=-2.313522\n",
      "[LightGBM] [Info] Start training from score -2.313522\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "[LightGBM] [Info] Number of positive: 4350, number of negative: 22725\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27075, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160665 -> initscore=-1.653290\n",
      "[LightGBM] [Info] Start training from score -1.653290\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "[LightGBM] [Info] Number of positive: 2850, number of negative: 24225\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27075, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.105263 -> initscore=-2.140066\n",
      "[LightGBM] [Info] Start training from score -2.140066\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "[LightGBM] [Info] Number of positive: 7614, number of negative: 19461\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27075, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.281219 -> initscore=-0.938424\n",
      "[LightGBM] [Info] Start training from score -0.938424\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "[LightGBM] [Info] Number of positive: 19157, number of negative: 7918\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27075, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.707553 -> initscore=0.883530\n",
      "[LightGBM] [Info] Start training from score 0.883530\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\kamim\\anaconda3\\envs\\py38\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "[LightGBM] [Info] Number of positive: 722, number of negative: 26353\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27075, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.026667 -> initscore=-3.597312\n",
      "[LightGBM] [Info] Start training from score -3.597312\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "         ETT - Abnormal ETT - Borderline ETT - Normal NGT - Abnormal  \\\nfold - 0       0.980692         0.969549     0.995741       0.901422   \nfold - 1       0.878253         0.963632     0.992435       0.904422   \nfold - 2       0.981322         0.961637     0.991482       0.866276   \nfold - 3       0.967665         0.965229     0.995102         0.9186   \n\n         NGT - Borderline NGT - Incompletely Imaged NGT - Normal  \\\nfold - 0         0.920396                  0.976525     0.975013   \nfold - 1         0.895277                  0.978161     0.976253   \nfold - 2         0.895654                  0.976734     0.970884   \nfold - 3         0.912445                  0.982528     0.980811   \n\n         CVC - Abnormal CVC - Borderline CVC - Normal  \\\nfold - 0       0.846312         0.786867     0.857186   \nfold - 1       0.858665         0.823853     0.868736   \nfold - 2       0.858952         0.823529     0.864922   \nfold - 3       0.838656         0.822641     0.875814   \n\n         Swan Ganz Catheter Present  \nfold - 0                   0.999443  \nfold - 1                   0.999914  \nfold - 2                   0.999623  \nfold - 3                   0.997596  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ETT - Abnormal</th>\n      <th>ETT - Borderline</th>\n      <th>ETT - Normal</th>\n      <th>NGT - Abnormal</th>\n      <th>NGT - Borderline</th>\n      <th>NGT - Incompletely Imaged</th>\n      <th>NGT - Normal</th>\n      <th>CVC - Abnormal</th>\n      <th>CVC - Borderline</th>\n      <th>CVC - Normal</th>\n      <th>Swan Ganz Catheter Present</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>fold - 0</th>\n      <td>0.980692</td>\n      <td>0.969549</td>\n      <td>0.995741</td>\n      <td>0.901422</td>\n      <td>0.920396</td>\n      <td>0.976525</td>\n      <td>0.975013</td>\n      <td>0.846312</td>\n      <td>0.786867</td>\n      <td>0.857186</td>\n      <td>0.999443</td>\n    </tr>\n    <tr>\n      <th>fold - 1</th>\n      <td>0.878253</td>\n      <td>0.963632</td>\n      <td>0.992435</td>\n      <td>0.904422</td>\n      <td>0.895277</td>\n      <td>0.978161</td>\n      <td>0.976253</td>\n      <td>0.858665</td>\n      <td>0.823853</td>\n      <td>0.868736</td>\n      <td>0.999914</td>\n    </tr>\n    <tr>\n      <th>fold - 2</th>\n      <td>0.981322</td>\n      <td>0.961637</td>\n      <td>0.991482</td>\n      <td>0.866276</td>\n      <td>0.895654</td>\n      <td>0.976734</td>\n      <td>0.970884</td>\n      <td>0.858952</td>\n      <td>0.823529</td>\n      <td>0.864922</td>\n      <td>0.999623</td>\n    </tr>\n    <tr>\n      <th>fold - 3</th>\n      <td>0.967665</td>\n      <td>0.965229</td>\n      <td>0.995102</td>\n      <td>0.9186</td>\n      <td>0.912445</td>\n      <td>0.982528</td>\n      <td>0.980811</td>\n      <td>0.838656</td>\n      <td>0.822641</td>\n      <td>0.875814</td>\n      <td>0.997596</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0.9272011609223824"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import lightgbm\n",
    "\n",
    "num_features=100\n",
    "\n",
    "def get_pred(train,val,col_idx:int):\n",
    "    X_train,y_train=train\n",
    "    X_val,y_val=val\n",
    "    col_name=CFG.target_cols[col_idx]\n",
    "    y_train_col,y_val_col=y_train[col_name],y_val[col_name]\n",
    "\n",
    "    lgb_train=lightgbm.Dataset(X_train,label=y_train_col)\n",
    "    lgb_test=lightgbm.Dataset(X_val,label=y_val_col,reference=lgb_train)\n",
    "\n",
    "    params=pickle.load(open(f\"{CFG.models_dir}lgbm_effnet_best/params_{col_idx}.pickle\",\"rb\"))\n",
    "    params[\"early_stopping_rounds\"]=1000\n",
    "\n",
    "    model=lightgbm.train(params,lgb_train,valid_sets=lgb_test,verbose_eval=False)\n",
    "    pred=model.predict(X_val)\n",
    "    auc=roc_auc_score(y_val_col,pred)\n",
    "\n",
    "    return pred,auc\n",
    "\n",
    "\n",
    "results=pd.DataFrame(columns=CFG.target_cols)\n",
    "\n",
    "for n in range(4):\n",
    "    print(f\"\\nfold - {n}\")\n",
    "    train_idx=(fold[\"folds\"]!=n)\n",
    "    val_idx=(fold[\"folds\"]==n)\n",
    "    X_train,X_val=X_dropped[train_idx],X_dropped[val_idx]\n",
    "    y_train,y_val=train[train_idx],train[val_idx] \n",
    "\n",
    "    for col_idx,col_name in enumerate(CFG.target_cols):\n",
    "        _,auc=get_pred(train=(X_train,y_train),val=(X_val,y_val),col_idx=col_idx)\n",
    "        results.loc[f\"fold - {n}\",col_name]=auc\n",
    "\n",
    "\n",
    "display(results,results.mean(axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "         ETT - Abnormal ETT - Borderline ETT - Normal NGT - Abnormal  \\\nfold - 0       0.973369         0.973097     0.995879       0.907734   \nfold - 1       0.958959          0.96286     0.992628       0.918469   \nfold - 2       0.983535         0.962376      0.99177       0.879977   \nfold - 3       0.938969         0.965897     0.994806       0.927158   \nfold - 4       0.881985         0.969985     0.993558       0.904481   \n\n         NGT - Borderline NGT - Incompletely Imaged NGT - Normal  \\\nfold - 0         0.917653                  0.978197     0.975421   \nfold - 1         0.897845                  0.979059     0.976285   \nfold - 2         0.900918                  0.977728     0.970469   \nfold - 3         0.918764                  0.982168     0.980094   \nfold - 4         0.910657                  0.978309     0.981756   \n\n         CVC - Abnormal CVC - Borderline CVC - Normal  \\\nfold - 0       0.847992         0.791439      0.85961   \nfold - 1       0.858765          0.81947     0.868902   \nfold - 2         0.8574         0.818245     0.868019   \nfold - 3       0.836751         0.818852     0.876296   \nfold - 4       0.856186         0.821953     0.886719   \n\n         Swan Ganz Catheter Present  \nfold - 0                   0.999596  \nfold - 1                   0.999873  \nfold - 2                   0.998987  \nfold - 3                   0.995032  \nfold - 4                   0.998934  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ETT - Abnormal</th>\n      <th>ETT - Borderline</th>\n      <th>ETT - Normal</th>\n      <th>NGT - Abnormal</th>\n      <th>NGT - Borderline</th>\n      <th>NGT - Incompletely Imaged</th>\n      <th>NGT - Normal</th>\n      <th>CVC - Abnormal</th>\n      <th>CVC - Borderline</th>\n      <th>CVC - Normal</th>\n      <th>Swan Ganz Catheter Present</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>fold - 0</th>\n      <td>0.973369</td>\n      <td>0.973097</td>\n      <td>0.995879</td>\n      <td>0.907734</td>\n      <td>0.917653</td>\n      <td>0.978197</td>\n      <td>0.975421</td>\n      <td>0.847992</td>\n      <td>0.791439</td>\n      <td>0.85961</td>\n      <td>0.999596</td>\n    </tr>\n    <tr>\n      <th>fold - 1</th>\n      <td>0.958959</td>\n      <td>0.96286</td>\n      <td>0.992628</td>\n      <td>0.918469</td>\n      <td>0.897845</td>\n      <td>0.979059</td>\n      <td>0.976285</td>\n      <td>0.858765</td>\n      <td>0.81947</td>\n      <td>0.868902</td>\n      <td>0.999873</td>\n    </tr>\n    <tr>\n      <th>fold - 2</th>\n      <td>0.983535</td>\n      <td>0.962376</td>\n      <td>0.99177</td>\n      <td>0.879977</td>\n      <td>0.900918</td>\n      <td>0.977728</td>\n      <td>0.970469</td>\n      <td>0.8574</td>\n      <td>0.818245</td>\n      <td>0.868019</td>\n      <td>0.998987</td>\n    </tr>\n    <tr>\n      <th>fold - 3</th>\n      <td>0.938969</td>\n      <td>0.965897</td>\n      <td>0.994806</td>\n      <td>0.927158</td>\n      <td>0.918764</td>\n      <td>0.982168</td>\n      <td>0.980094</td>\n      <td>0.836751</td>\n      <td>0.818852</td>\n      <td>0.876296</td>\n      <td>0.995032</td>\n    </tr>\n    <tr>\n      <th>fold - 4</th>\n      <td>0.881985</td>\n      <td>0.969985</td>\n      <td>0.993558</td>\n      <td>0.904481</td>\n      <td>0.910657</td>\n      <td>0.978309</td>\n      <td>0.981756</td>\n      <td>0.856186</td>\n      <td>0.821953</td>\n      <td>0.886719</td>\n      <td>0.998934</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "fold - 0    0.929090\nfold - 1    0.930283\nfold - 2    0.928129\nfold - 3    0.930435\nfold - 4    0.925866\ndtype: float64"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(results,results.mean(axis=1))"
   ]
  },
  {
   "source": [
    "lgbm_effnet_tuned: 0.91343  \n",
    "lgbm_effnet_tuned_dropped: 0.914  \n",
    "lgbm_effnet_tuned_theta: 0.9099249788193785  \n",
    "lgbm_effnet_tuned_smallLR (dropped): 0.9155745942231474  \n",
    "lgbm_effnet_best_dropped: 0.9287606420966457  \n",
    "lgbm_effnet_best: 0.9272011609223824"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## モデルを保存する"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      ": -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6477, number of negative: 20597\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239233 -> initscore=-1.156888\n",
      "[LightGBM] [Info] Start training from score -1.156888\n",
      "[LightGBM] [Info] Number of positive: 244, number of negative: 26830\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.009012 -> initscore=-4.700108\n",
      "[LightGBM] [Info] Start training from score -4.700108\n",
      "[LightGBM] [Info] Number of positive: 464, number of negative: 26610\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.017138 -> initscore=-4.049158\n",
      "[LightGBM] [Info] Start training from score -4.049158\n",
      "[LightGBM] [Info] Number of positive: 2425, number of negative: 24649\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089569 -> initscore=-2.318905\n",
      "[LightGBM] [Info] Start training from score -2.318905\n",
      "[LightGBM] [Info] Number of positive: 4284, number of negative: 22790\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.158233 -> initscore=-1.671435\n",
      "[LightGBM] [Info] Start training from score -1.671435\n",
      "[LightGBM] [Info] Number of positive: 2902, number of negative: 24172\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.107188 -> initscore=-2.119795\n",
      "[LightGBM] [Info] Start training from score -2.119795\n",
      "[LightGBM] [Info] Number of positive: 7533, number of negative: 19541\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.278237 -> initscore=-0.953221\n",
      "[LightGBM] [Info] Start training from score -0.953221\n",
      "[LightGBM] [Info] Number of positive: 19135, number of negative: 7939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.706767 -> initscore=0.879732\n",
      "[LightGBM] [Info] Start training from score 0.879732\n",
      "[LightGBM] [Info] Number of positive: 761, number of negative: 26313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15555\n",
      "[LightGBM] [Info] Number of data points in the train set: 27074, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028108 -> initscore=-3.543185\n",
      "[LightGBM] [Info] Start training from score -3.543185\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "\n",
    "target_fold=0\n",
    "train_idx=(fold[\"folds\"]!=target_fold)\n",
    "val_idx=(fold[\"folds\"]==target_fold)\n",
    "\n",
    "X_train,X_val=X_dropped[train_idx],X_dropped[val_idx]\n",
    "y_train,y_val=train[train_idx],train[val_idx]\n",
    "\n",
    "for i,col_name in enumerate(CFG.target_cols):\n",
    "    y_train_col=y_train[col_name]\n",
    "    y_val_col=y_val[col_name]\n",
    "\n",
    "    lgb_train=lightgbm.Dataset(X_train,label=y_train_col)\n",
    "    lgb_val=lightgbm.Dataset(X_val,label=y_val_col,reference=lgb_train)\n",
    "    \n",
    "    params=pickle.load(open(f\"{CFG.models_dir}lgbm_effnet_best_dropped/params_{i}.pickle\",\"rb\"))    \n",
    "    params[\"early_stopping_rounds\"]=1000\n",
    "\n",
    "    model=lightgbm.train(params,lgb_train,valid_sets=lgb_val,verbose_eval=False)\n",
    "    pickle.dump(model,open(f\"{CFG.models_dir}lgbm_effnet_best_dropped/model_{i}.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Int64Index([ 3,  4,  6,  8,  9, 13, 14, 17, 18, 23, 27, 35, 36, 37, 38, 44, 45,\n            47, 50, 51, 52, 57, 58, 61, 62, 68, 72, 73, 74, 76, 85, 86, 87, 90,\n            91, 92, 98, 99],\n           dtype='int64')"
     },
     "metadata": {}
    }
   ],
   "source": [
    "importances=pd.DataFrame(columns=CFG.target_cols)\n",
    "\n",
    "for i,col_name in enumerate(CFG.target_cols):\n",
    "    model=pickle.load(open(f\"./models/lgbm_effnet_best/model_{i}.pickle\",\"rb\"))\n",
    "    importances[col_name]=pd.Series(model.feature_importance())\n",
    "\n",
    "valueless_rows=importances.where(importances.sum(axis=1)==0).dropna(how=\"all\")\n",
    "display(valueless_rows.index)"
   ]
  }
 ]
}