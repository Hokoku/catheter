{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","from IPython.display import display\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import tensorflow.keras.applications.efficientnet as efn\n","from sklearn.model_selection import GroupKFold"],"execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Helper functions"]},{"metadata":{},"cell_type":"markdown","source":["## Variables and configurations"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def auto_select_accelerator():\n","    try:\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","        tf.config.experimental_connect_to_cluster(tpu)\n","        tf.tpu.experimental.initialize_tpu_system(tpu)\n","        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","        print(\"Running on TPU:\", tpu.master())\n","    except ValueError:\n","        strategy = tf.distribute.get_strategy()\n","    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n","    \n","    return strategy\n","\n","\n","def build_decoder(with_labels=True, target_size=(256, 256), ext='jpg'):\n","    def decode(path):\n","        file_bytes = tf.io.read_file(path)\n","        if ext == 'png':\n","            img = tf.image.decode_png(file_bytes, channels=3)\n","        elif ext in ['jpg', 'jpeg']:\n","            img = tf.image.decode_jpeg(file_bytes, channels=3)\n","        else:\n","            raise ValueError(\"Image extension not supported\")\n","\n","        img = tf.cast(img, tf.float32) / 255.0\n","        img = tf.image.resize(img, target_size)\n","\n","        return img\n","    \n","    def decode_with_labels(path, label):\n","        return decode(path), label\n","    \n","    return decode_with_labels if with_labels else decode\n","\n","\n","def build_augmenter(with_labels=True):\n","    def augment(img):\n","        img = tf.image.random_flip_left_right(img)\n","        img = tf.image.random_flip_up_down(img)\n","        return img\n","    \n","    def augment_with_labels(img, label):\n","        return augment(img), label\n","    \n","    return augment_with_labels if with_labels else augment\n","\n","\n","def build_dataset(paths, labels=None, bsize=32, cache=True,\n","                  decode_fn=None, augment_fn=None,\n","                  augment=True, repeat=True, shuffle=1024, \n","                  cache_dir=\"\"):\n","    if cache_dir != \"\" and cache is True:\n","        os.makedirs(cache_dir, exist_ok=True)\n","    \n","    if decode_fn is None:\n","        decode_fn = build_decoder(labels is not None)\n","    \n","    if augment_fn is None:\n","        augment_fn = build_augmenter(labels is not None)\n","    \n","    AUTO = tf.data.experimental.AUTOTUNE\n","    slices = paths if labels is None else (paths, labels)\n","    \n","    dset = tf.data.Dataset.from_tensor_slices(slices)\n","    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n","    dset = dset.cache(cache_dir) if cache else dset\n","    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n","    dset = dset.repeat() if repeat else dset\n","    dset = dset.shuffle(shuffle) if shuffle else dset\n","    dset = dset.batch(bsize).prefetch(AUTO)\n","    \n","    return dset"]},{"metadata":{"trusted":true},"cell_type":"code","source":["strategy = auto_select_accelerator()\n","\n","debug=True\n","\n","COMPETITION_NAME = \"ranzcr-clip-catheter-line-classification\"\n","BATCH_SIZE = 8 if debug else strategy.num_replicas_in_sync * 16\n","n_folds=10\n","if not debug:\n","    from kaggle_datasets import KaggleDatasets\n","    GCS_DS_PATH = KaggleDatasets().get_gcs_path(COMPETITION_NAME)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on 1 replicas\n"]}]},{"metadata":{},"cell_type":"markdown","source":["## Preparing dataset"]},{"metadata":{},"cell_type":"markdown","source":["### Loading and preprocess CSVs"]},{"metadata":{"trusted":true},"cell_type":"code","source":["load_dir = \"../input/ranzcr-clip-catheter-line-classification\" if debug else f\"/kaggle/input/{COMPETITION_NAME}\"\n","df = pd.read_csv(f\"{load_dir}/train.csv\")\n","\n","# paths = load_dir + \"train/\" + df['StudyInstanceUID'] + '.jpg'\n","paths = f\"{load_dir}/train/\"+df[\"StudyInstanceUID\"]+\".jpg\" if debug \\\n","    else f\"{GCS_DS_PATH}/train/\" + df['StudyInstanceUID'] + '.jpg'\n","\n","sub_df = pd.read_csv(f\"{load_dir}/sample_submission.csv\")\n","\n","# test_paths = load_dir + \"test/\" + sub_df['StudyInstanceUID'] + '.jpg'\n","test_paths = f\"{load_dir}/train/\"+df[\"StudyInstanceUID\"]+\".jpg\" if debug \\\n","    else f\"{GCS_DS_PATH}/test/\" + sub_df['StudyInstanceUID'] + '.jpg'\n","\n","# Get the multi-labels\n","label_cols = sub_df.columns[1:]\n","labels = df[label_cols].values"],"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def get_fold(train):\n","    fold=train.copy()\n","    splitter=GroupKFold(n_splits=n_folds)\n","    for n,(train_idx,val_idx) in enumerate(splitter.split(train,groups=train[\"PatientID\"])):\n","        fold.loc[val_idx,\"folds\"]=n\n","    fold[\"folds\"]=fold[\"folds\"].astype(int)\n","    return fold\n","\n","fold=get_fold(df)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["target_fold=0\n","\n","train_idx=(fold[\"folds\"]!=target_fold)\n","val_idx=(fold[\"folds\"]==target_fold)\n","\n","train_paths=paths[train_idx]\n","valid_paths=paths[val_idx]\n","\n","train_labels=labels[train_idx]\n","valid_labels=labels[val_idx]"],"execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# データの処理"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Build the tensorflow datasets\n","IMSIZES = (224, 240, 260, 300, 380, 456, 528, 600)\n","im_size = IMSIZES[7]\n","\n","decoder = build_decoder(with_labels=True, target_size=(im_size, im_size))\n","test_decoder = build_decoder(with_labels=False, target_size=(im_size, im_size))\n","\n","train_dataset = build_dataset(\n","    train_paths, train_labels, bsize=BATCH_SIZE, decode_fn=decoder\n",")\n","\n","valid_dataset = build_dataset(\n","    valid_paths, valid_labels, bsize=BATCH_SIZE, decode_fn=decoder,\n","    repeat=False, shuffle=False, augment=False\n",")"],"execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Modeling"]},{"metadata":{"trusted":true},"cell_type":"code","source":["n_labels = labels.shape[1]\n","def create_model(drop_connect_rate):  \n","    with strategy.scope():\n","        model = tf.keras.Sequential([\n","            efn.EfficientNetB7(\n","                input_shape=(im_size, im_size, 3),\n","                weights='imagenet',\n","                include_top=False,\n","                drop_connect_rate=drop_connect_rate), ##\n","            tf.keras.layers.GlobalAveragePooling2D(),\n","            tf.keras.layers.Dense(n_labels, activation='sigmoid')\n","        ])\n","        model.compile(\n","            optimizer='adam',\n","            loss='binary_crossentropy',\n","            metrics=[tf.keras.metrics.AUC(multi_label=True,name=\"auc\")])\n","    return model"],"execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import optuna\n","\n","lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n","    monitor=\"val_auc\", patience=3, min_lr=1e-6, mode='max')\n","checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5',\n","    save_best_only=True, monitor='val_auc', mode='max')\n","steps_per_epoch = train_paths.shape[0] // BATCH_SIZE\n","\n","def objective(trial):\n","    keras.backend.clear_session() # clear session and release memory\n","    \n","    #最適化するパラメータの設定\n","    drop_connect_rate=trial.suggest_uniform(\"drop_connect_rate\", 0.0, 0.4)         \n","    model = create_model(drop_connect_rate=drop_connect_rate)\n","\n","        \n","    history = model.fit(\n","        train_dataset, \n","        epochs=10,\n","        verbose=1,\n","        callbacks= [lr_reducer],\n","        steps_per_epoch=steps_per_epoch,\n","        validation_data=valid_dataset)\n","\n","    auc=model.evaluate(valid_dataset)\n","    \n","    return auc"],"execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=30)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2021-03-11 23:10:49,107]\u001b[0m A new study created in memory with name: no-name-872da57a-b0b9-4346-afe1-9eb6fac4ec4d\u001b[0m\n","Epoch 1/10\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":["result_df=study.trials_dataframe()\n","result_df.to_csv('efficientnetB7_optuna_history.csv')"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.8-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}