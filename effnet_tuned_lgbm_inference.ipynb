{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('py38': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3da45907e5cd41bdac7b692b424c19725633d98a853f93b11b400b1d8951ac30"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "   debug=True\n",
    "   dataset_dir=\"../input/ranzcr-clip-catheter-line-classification/\"\n",
    "   models_dir=\"./models/\" if debug else \"../input/efficientnet-lightgbm-models/\"\n",
    "   batch_size=4 if debug else 256\n",
    "   input_shape=(260,260)\n",
    "\n",
    "   target_cols=['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', 'NGT - Abnormal', 'NGT - Borderline',\n",
    "      'NGT - Incompletely Imaged', 'NGT - Normal', 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal', 'Swan Ganz Catheter Present']\n",
    "   n_folds=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(f\"{CFG.dataset_dir}train.csv\") if CFG.debug else pd.read_csv(f\"{CFG.dataset_dir}sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nefficientnetb7_input (InputL [(None, 260, 260, 3)]     0         \n_________________________________________________________________\nefficientnetb7 (Functional)  (None, 9, 9, 2560)        64097687  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 2560)              0         \n=================================================================\nTotal params: 64,097,687\nTrainable params: 63,786,960\nNon-trainable params: 310,727\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{CFG.models_dir}effnet_tuned/model.json\",\"rt\") as f:\n",
    "    effnet_json=f.read()\n",
    "effnet=models.model_from_json(effnet_json)\n",
    "effnet.load_weights(f\"{CFG.models_dir}effnet_tuned/weight.hdf5\")\n",
    "\n",
    "layer_name=\"global_average_pooling2d\"\n",
    "hidden_layer_model=models.Model(inputs=effnet.input,outputs=effnet.get_layer(layer_name).output)\n",
    "hidden_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(record):\n",
    "    if CFG.debug:\n",
    "        file_bytes=tf.io.read_file(f\"{CFG.dataset_dir}train/\"+record+\".jpg\") # f\"{}\"形式ではTensorの型変換が働かない\n",
    "    else:\n",
    "        file_bytes=tf.io.read_file(f\"{CFG.dataset_dir}test/\"+record+\".jpg\")\n",
    "    image=tf.io.decode_jpeg(file_bytes,channels=3)\n",
    "    image=tf.cast(image,tf.float32)\n",
    "    image=tf.image.resize(image,CFG.input_shape)\n",
    "    image/=255\n",
    "    return image\n",
    "\n",
    "def decode_string(tensor):\n",
    "    return [str_bytes.decode() for str_bytes in tensor.numpy()]\n",
    "\n",
    "\n",
    "dset=tf.data.Dataset.from_tensor_slices(test[\"StudyInstanceUID\"])\n",
    "dset=dset.map(preprocess,num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(CFG.batch_size)\n",
    "\n",
    "uid_dset=tf.data.Dataset.from_tensor_slices(test[\"StudyInstanceUID\"]).batch(CFG.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04bc090872764b5caebefb75d6059b5a"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "ndarray_dict={}\n",
    "for imgs,uids in tqdm(zip(dset,uid_dset)):\n",
    "    preds=hidden_layer_model.predict(imgs)\n",
    "    uids_decoded=decode_string(uids)\n",
    "    \n",
    "    for uid,pred in zip(uids_decoded,preds):\n",
    "        ndarray_dict[uid]=pred\n",
    "    if CFG.debug:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    features_list=[ndarray_dict[uid] for uid in ndarray_dict.keys()]\n",
    "else:\n",
    "    features_list=[ndarray_dict[uid] for uid in tqdm(test[\"StudyInstanceUID\"])]\n",
    "features=np.array(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "def compress_with_autoencoder(features):\n",
    "    scaler=pickle.load(open(\"./models/minmaxscaler_effnet_tuned.pickle\",\"rb\"))\n",
    "    X=scaler.transform(features)\n",
    "\n",
    "    autoencoder_dir=f\"{CFG.models_dir}autoencoder_tuned/\"\n",
    "    with open(f\"{autoencoder_dir}model.json\",\"rt\") as f:\n",
    "        model_json=f.read()\n",
    "    autoencoder=models.model_from_json(model_json)\n",
    "    autoencoder.load_weights(f\"{autoencoder_dir}ckpt\")\n",
    "\n",
    "    layer_name=\"dense_1\"\n",
    "    compressing_model=models.Model(inputs=autoencoder.input,outputs=autoencoder.get_layer(layer_name).output)\n",
    "\n",
    "    ae_pred=compressing_model.predict(X)\n",
    "    ae_pred_df=pd.DataFrame(ae_pred)\n",
    "\n",
    "    return ae_pred_df\n",
    "\n",
    "X=compress_with_autoencoder(features)\n",
    "\n",
    "valuless_columns=[4,  7,  9, 12, 13, 20, 25, 27, 30, 31, 36, 44, 47, 48, 51, 54, 64, 65, 71, 73, 74, 75, 89, 92, 97]\n",
    "X_dropped=X.drop(columns=valuless_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   ETT - Abnormal  ETT - Borderline  ETT - Normal  NGT - Abnormal  \\\n0        0.000210          0.000149      0.005456        0.049847   \n1        0.000073          0.011441      0.958750        0.045152   \n2        0.000029          0.000045      0.000403        0.000513   \n3        0.000098          0.000114      0.001296        0.001495   \n\n   NGT - Borderline  NGT - Incompletely Imaged  NGT - Normal  CVC - Abnormal  \\\n0          0.033515                   0.029808      0.946201        0.127565   \n1          0.013968                   0.847076      0.007410        0.030665   \n2          0.000573                   0.000468      0.000469        0.045540   \n3          0.000523                   0.001351      0.002090        0.534030   \n\n   CVC - Borderline  CVC - Normal  Swan Ganz Catheter Present  \n0          0.402328      0.232080                    0.000004  \n1          0.188236      0.920666                    0.000003  \n2          0.367712      0.650866                    0.000001  \n3          0.306914      0.256785                    0.000002  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ETT - Abnormal</th>\n      <th>ETT - Borderline</th>\n      <th>ETT - Normal</th>\n      <th>NGT - Abnormal</th>\n      <th>NGT - Borderline</th>\n      <th>NGT - Incompletely Imaged</th>\n      <th>NGT - Normal</th>\n      <th>CVC - Abnormal</th>\n      <th>CVC - Borderline</th>\n      <th>CVC - Normal</th>\n      <th>Swan Ganz Catheter Present</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000210</td>\n      <td>0.000149</td>\n      <td>0.005456</td>\n      <td>0.049847</td>\n      <td>0.033515</td>\n      <td>0.029808</td>\n      <td>0.946201</td>\n      <td>0.127565</td>\n      <td>0.402328</td>\n      <td>0.232080</td>\n      <td>0.000004</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000073</td>\n      <td>0.011441</td>\n      <td>0.958750</td>\n      <td>0.045152</td>\n      <td>0.013968</td>\n      <td>0.847076</td>\n      <td>0.007410</td>\n      <td>0.030665</td>\n      <td>0.188236</td>\n      <td>0.920666</td>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000029</td>\n      <td>0.000045</td>\n      <td>0.000403</td>\n      <td>0.000513</td>\n      <td>0.000573</td>\n      <td>0.000468</td>\n      <td>0.000469</td>\n      <td>0.045540</td>\n      <td>0.367712</td>\n      <td>0.650866</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000098</td>\n      <td>0.000114</td>\n      <td>0.001296</td>\n      <td>0.001495</td>\n      <td>0.000523</td>\n      <td>0.001351</td>\n      <td>0.002090</td>\n      <td>0.534030</td>\n      <td>0.306914</td>\n      <td>0.256785</td>\n      <td>0.000002</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "submission=pd.DataFrame(columns=CFG.target_cols) if CFG.debug else test.copy()\n",
    "\n",
    "for i,col_name in enumerate(CFG.target_cols):\n",
    "    lgbm_model=pickle.load(open(f\"{CFG.models_dir}lgbm_effnet_tuned_dropped/model_{i}.pickle\",\"rb\"))\n",
    "    pred=lgbm_model.predict(X_dropped)\n",
    "    submission[col_name]=pred\n",
    "\n",
    "display(submission)\n",
    "\n",
    "if not CFG.debug:\n",
    "    submission.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ]
}