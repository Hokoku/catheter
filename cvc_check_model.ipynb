{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('py38': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3da45907e5cd41bdac7b692b424c19725633d98a853f93b11b400b1d8951ac30"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    debug=True\n",
    "\n",
    "    dataset_dir=\"../input/ranzcr-clip-catheter-line-classification/\"\n",
    "    batch_size=4 if debug else 64 \n",
    "    input_size=(576,576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(f\"{CFG.dataset_dir}train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    custom_objects={\n",
    "        \"iou_score\":sm.metrics.IOUScore,\n",
    "        \"binary_crossentropy_plus_jaccard_loss\":sm.losses.bce_jaccard_loss\n",
    "    }\n",
    "    model=tf.keras.models.load_model(\"./models/pspnet_ckpt\", custom_objects=custom_objects)\n",
    "    # model=sm.PSPNet(classes=1,activation=\"sigmoid\",encoder_weights=None,input_shape=CFG.input_size+(1,))\n",
    "    # model.compile(optimizer=\"adam\",loss=sm.losses.bce_jaccard_loss,metrics=[sm.metrics.iou_score])\n",
    "    return model\n",
    "\n",
    "pspnet=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO=tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def preprocess(uid):\n",
    "    path=f\"{CFG.dataset_dir}train/\"+uid+\".jpg\"\n",
    "    file_bytes=tf.io.read_file(path)\n",
    "    img=tf.io.decode_jpeg(file_bytes)\n",
    "    img=tf.image.resize(img,CFG.input_size)\n",
    "    img/=255.0\n",
    "\n",
    "    return uid,img\n",
    "\n",
    "def build_dataset(uids,shuffle=256):\n",
    "    dset=tf.data.Dataset.from_tensor_slices(uids)\n",
    "    dset=dset.map(preprocess,num_parallel_calls=AUTO)\n",
    "    dset=dset.cache()\n",
    "    dset=dset.shuffle(shuffle) if shuffle else dset\n",
    "    dset=dset.batch(CFG.batch_size,drop_remainder=True).prefetch(AUTO)\n",
    "    return dset\n",
    "\n",
    "def decode_str_tensors(tensors):\n",
    "    return [tensor.numpy().decode() for tensor in tensors]\n",
    "\n",
    "dset=build_dataset(train[\"StudyInstanceUID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_show(img,title=None):\n",
    "    fig,ax=plt.subplots(1,1,figsize=(5,5))\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(title)\n",
    "    # save_dir=\"../input/cvc_pspnet_pred/\"\n",
    "    # os.makedirs(save_dir,exist_ok=True)\n",
    "    #fig.savefig(save_dir+title+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uids,imgs in dset.take(1):\n",
    "    uids_decoded=decode_str_tensors(uids)\n",
    "    preds=pspnet.predict(imgs)\n",
    "\n",
    "    merged_imgs=[]\n",
    "    for uid,pred in zip(uids_decoded,preds):\n",
    "        pred=pred.reshape(pred.shape[0],pred.shape[1])\n",
    "        stacked_img=np.stack((pred,)*3,axis=-1)\n",
    "        stacked_img[:,:,(1,2)]=0\n",
    "\n",
    "        train_file_bytes=tf.io.read_file(f\"../input/ranzcr-clip-catheter-line-classification/train/{uid}.jpg\")\n",
    "        train_img=tf.io.decode_jpeg(train_file_bytes,channels=3)\n",
    "        train_img=tf.image.resize(train_img,(576,576))\n",
    "        train_img/=255.0\n",
    "\n",
    "        merged_img=train_img+stacked_img\n",
    "        merged_img=merged_img.numpy()\n",
    "        merged_img=np.where(merged_img>1,1,merged_img) # 加算によって通常の範囲を超えた値を制限する\n",
    "        merged_imgs.append(merged_img)\n",
    "\n",
    "    for uid,img in zip(uids_decoded,merged_imgs):\n",
    "        img_multi=img*255.0\n",
    "        img_uint8=tf.cast(img_multi,tf.uint8)\n",
    "        img_png=tf.io.encode_png(img_uint8)\n",
    "        tf.io.write_file(f\"../input/cvc_rendered_576x576/{uid}.png\",img_png)\n",
    "    # cvc_pred=effnet_cvc.predict(merged_imgs)"
   ]
  }
 ]
}